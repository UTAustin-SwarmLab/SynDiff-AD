{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this script to generate a scv that merges the data from all CSVs\n",
    "\n",
    "#used for llava captioning and synthetic data generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WAYMO LLAVA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH= \"../waymo_open_data/\"\n",
    "if os.path.exists(PATH):\n",
    "    files = os.listdir(PATH)\n",
    "    \n",
    "df_list = []\n",
    "file_names = []\n",
    "for f in files:\n",
    "    if f.endswith(\".csv\"):\n",
    "        fname = f.split(\".\")[0]\n",
    "        if len(fname.split(\"_\"))==4 and fname.split(\"_\")[1]==\"captions\":\n",
    "            file_names = fname.split(\"_\")[:-1]\n",
    "            df_list.append(pd.read_csv(PATH+f))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[                                content_name     context_frame  camera_id  \\\n",
      "0     10017090168044687777_6380_000_6400_000  1550083474648906          1   \n",
      "1     10017090168044687777_6380_000_6400_000  1550083474648906          2   \n",
      "2     10017090168044687777_6380_000_6400_000  1550083475049006          0   \n",
      "3     10017090168044687777_6380_000_6400_000  1550083475049006          1   \n",
      "4     10017090168044687777_6380_000_6400_000  1550083475049006          2   \n",
      "...                                      ...               ...        ...   \n",
      "6635   9985243312780923024_3049_720_3069_720  1507312253230489          1   \n",
      "6636   9985243312780923024_3049_720_3069_720  1507312253230489          2   \n",
      "6637   9985243312780923024_3049_720_3069_720  1507312253430455          0   \n",
      "6638   9985243312780923024_3049_720_3069_720  1507312253430455          1   \n",
      "6639   9985243312780923024_3049_720_3069_720  1507312253430455          2   \n",
      "\n",
      "                                                caption  \n",
      "0      This image is taken during  Day time of the d...  \n",
      "1      This image is taken during  Day time of the d...  \n",
      "2      This image is taken during  Day time of the d...  \n",
      "3      This image is taken during  Day time of the d...  \n",
      "4      This image is taken during  Day time of the d...  \n",
      "...                                                 ...  \n",
      "6635   This image is taken during  Day time of the d...  \n",
      "6636   This image is taken during  Day time of the d...  \n",
      "6637   This image is taken during  Day time of the d...  \n",
      "6638   This image is taken during  Day time of the d...  \n",
      "6639   This image is taken during  Day time of the d...  \n",
      "\n",
      "[6640 rows x 4 columns],                                 content_name     context_frame  camera_id  \\\n",
      "0     10017090168044687777_6380_000_6400_000  1550083469645130          0   \n",
      "1     10017090168044687777_6380_000_6400_000  1550083469645130          1   \n",
      "2     10017090168044687777_6380_000_6400_000  1550083469645130          2   \n",
      "3     10017090168044687777_6380_000_6400_000  1550083470045260          0   \n",
      "4     10017090168044687777_6380_000_6400_000  1550083470045260          1   \n",
      "...                                      ...               ...        ...   \n",
      "6605     990914685337955114_980_000_1000_000  1557853483321004          2   \n",
      "6606     990914685337955114_980_000_1000_000  1557853483519873          0   \n",
      "6607     990914685337955114_980_000_1000_000  1557853483519873          1   \n",
      "6608   9985243312780923024_3049_720_3069_720  1507312258830731          1   \n",
      "6609   9985243312780923024_3049_720_3069_720  1507312258830731          2   \n",
      "\n",
      "                                                caption  \n",
      "0      This image is taken during  Day time of the d...  \n",
      "1      This image is taken during  Day time of the d...  \n",
      "2      This image is taken during  Day time of the d...  \n",
      "3      This image is taken during  Day time of the d...  \n",
      "4      This image is taken during  Day time of the d...  \n",
      "...                                                 ...  \n",
      "6605   This image is taken during  Day time of the d...  \n",
      "6606   This image is taken during  Day time of the d...  \n",
      "6607   This image is taken during  Day time of the d...  \n",
      "6608   This image is taken during  Day time of the d...  \n",
      "6609   This image is taken during  Day time of the d...  \n",
      "\n",
      "[6610 rows x 4 columns],                                 content_name     context_frame  camera_id  \\\n",
      "0     10023947602400723454_1120_000_1140_000  1552440198161543          1   \n",
      "1     10023947602400723454_1120_000_1140_000  1552440198161543          2   \n",
      "2     10023947602400723454_1120_000_1140_000  1552440198361627          0   \n",
      "3     10023947602400723454_1120_000_1140_000  1552440198361627          1   \n",
      "4     10023947602400723454_1120_000_1140_000  1552440198361627          2   \n",
      "...                                      ...               ...        ...   \n",
      "6571     990914685337955114_980_000_1000_000  1557853488296978          1   \n",
      "6572     990914685337955114_980_000_1000_000  1557853488296978          2   \n",
      "6573     990914685337955114_980_000_1000_000  1557853488497033          0   \n",
      "6574     990914685337955114_980_000_1000_000  1557853488497033          1   \n",
      "6575     990914685337955114_980_000_1000_000  1557853488497033          2   \n",
      "\n",
      "                                                caption  \n",
      "0      This image is taken during  Day time of the d...  \n",
      "1      This image is taken during  Day time of the d...  \n",
      "2      This image is taken during  Day time of the d...  \n",
      "3      This image is taken during  Day time of the d...  \n",
      "4      This image is taken during  Day time of the d...  \n",
      "...                                                 ...  \n",
      "6571   This image is taken during  Day time of the d...  \n",
      "6572   This image is taken during  Day time of the d...  \n",
      "6573   This image is taken during  Day time of the d...  \n",
      "6574   This image is taken during  Day time of the d...  \n",
      "6575   This image is taken during  Day time of the d...  \n",
      "\n",
      "[6576 rows x 4 columns],                                 content_name     context_frame  camera_id  \\\n",
      "0     10023947602400723454_1120_000_1140_000  1552440203162558          2   \n",
      "1     10023947602400723454_1120_000_1140_000  1552440203362569          0   \n",
      "2     10023947602400723454_1120_000_1140_000  1552440203362569          1   \n",
      "3     10023947602400723454_1120_000_1140_000  1552440203362569          2   \n",
      "4     10023947602400723454_1120_000_1140_000  1552440203562534          0   \n",
      "...                                      ...               ...        ...   \n",
      "6587   9985243312780923024_3049_720_3069_720  1507312258230661          2   \n",
      "6588   9985243312780923024_3049_720_3069_720  1507312258430720          0   \n",
      "6589   9985243312780923024_3049_720_3069_720  1507312258430720          1   \n",
      "6590   9985243312780923024_3049_720_3069_720  1507312258430720          2   \n",
      "6591   9985243312780923024_3049_720_3069_720  1507312258830731          0   \n",
      "\n",
      "                                                caption  \n",
      "0      This image is taken during  Day time of the d...  \n",
      "1      This image is taken during  Day time of the d...  \n",
      "2      This image is taken during  Day time of the d...  \n",
      "3      This image is taken during  Day time of the d...  \n",
      "4      This image is taken during  Day time of the d...  \n",
      "...                                                 ...  \n",
      "6587   This image is taken during  Day time of the d...  \n",
      "6588   This image is taken during  Day time of the d...  \n",
      "6589   This image is taken during  Day time of the d...  \n",
      "6590   This image is taken during  Day time of the d...  \n",
      "6591   This image is taken during  Day time of the d...  \n",
      "\n",
      "[6592 rows x 4 columns],                                 content_name     context_frame  camera_id  \\\n",
      "0     10017090168044687777_6380_000_6400_000  1550083485048877          0   \n",
      "1     10017090168044687777_6380_000_6400_000  1550083485048877          1   \n",
      "2     10017090168044687777_6380_000_6400_000  1550083485048877          2   \n",
      "3     10017090168044687777_6380_000_6400_000  1550083485248890          0   \n",
      "4     10017090168044687777_6380_000_6400_000  1550083485248890          1   \n",
      "...                                      ...               ...        ...   \n",
      "6587   9985243312780923024_3049_720_3069_720  1507312243030216          2   \n",
      "6588   9985243312780923024_3049_720_3069_720  1507312243230065          0   \n",
      "6589   9985243312780923024_3049_720_3069_720  1507312243230065          1   \n",
      "6590   9985243312780923024_3049_720_3069_720  1507312243230065          2   \n",
      "6591   9985243312780923024_3049_720_3069_720  1507312243429992          0   \n",
      "\n",
      "                                                caption  \n",
      "0      This image is taken during  Day time of the d...  \n",
      "1      This image is taken during  Day time of the d...  \n",
      "2      This image is taken during  Day time of the d...  \n",
      "3      This image is taken during  Day time of the d...  \n",
      "4      This image is taken during  Day time of the d...  \n",
      "...                                                 ...  \n",
      "6587   This image is taken during  Day time of the d...  \n",
      "6588   This image is taken during  Day time of the d...  \n",
      "6589   This image is taken during  Day time of the d...  \n",
      "6590   This image is taken during  Day time of the d...  \n",
      "6591   This image is taken during  Day time of the d...  \n",
      "\n",
      "[6592 rows x 4 columns],                                 content_name     context_frame  camera_id  \\\n",
      "0     10017090168044687777_6380_000_6400_000  1550083479648989          2   \n",
      "1     10017090168044687777_6380_000_6400_000  1550083480049065          0   \n",
      "2     10017090168044687777_6380_000_6400_000  1550083480049065          1   \n",
      "3     10017090168044687777_6380_000_6400_000  1550083480049065          2   \n",
      "4     10017090168044687777_6380_000_6400_000  1550083480249090          0   \n",
      "...                                      ...               ...        ...   \n",
      "6603   9985243312780923024_3049_720_3069_720  1507312248230443          0   \n",
      "6604   9985243312780923024_3049_720_3069_720  1507312248230443          1   \n",
      "6605   9985243312780923024_3049_720_3069_720  1507312248230443          2   \n",
      "6606   9985243312780923024_3049_720_3069_720  1507312248430481          0   \n",
      "6607   9985243312780923024_3049_720_3069_720  1507312248430481          1   \n",
      "\n",
      "                                                caption  \n",
      "0      This image is taken during  Day time of the d...  \n",
      "1      This image is taken during  Day time of the d...  \n",
      "2      This image is taken during  Day time of the d...  \n",
      "3      This image is taken during  Day time of the d...  \n",
      "4      This image is taken during  Day time of the d...  \n",
      "...                                                 ...  \n",
      "6603   This image is taken during  Day time of the d...  \n",
      "6604   This image is taken during  Day time of the d...  \n",
      "6605   This image is taken during  Day time of the d...  \n",
      "6606   This image is taken during  Day time of the d...  \n",
      "6607   This image is taken during  Day time of the d...  \n",
      "\n",
      "[6608 rows x 4 columns]]\n",
      "['waymo', 'captions', 'train']\n"
     ]
    }
   ],
   "source": [
    "print(df_list)\n",
    "print(file_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.concat(df_list, axis=0)\n",
    "merged_df.to_csv(PATH+\"{}_{}_{}.csv\".format(file_names[0],file_names[1],file_names[2]), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39618\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(PATH+\"{}_{}_{}.csv\".format(file_names[0],file_names[1],file_names[2]))\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BDD LLAVA\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No objects to concatenate",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/hg22723/projects/lang-cond-task-adv-augmentation/lang_cond_task_adv_augmentation/lang_data_synthesis/merge_files.ipynb Cell 9\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bswarmcluster1.ece.utexas.edu/home/hg22723/projects/lang-cond-task-adv-augmentation/lang_cond_task_adv_augmentation/lang_data_synthesis/merge_files.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m             file_names \u001b[39m=\u001b[39m fname\u001b[39m.\u001b[39msplit(\u001b[39m\"\u001b[39m\u001b[39m_\u001b[39m\u001b[39m\"\u001b[39m)[:\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bswarmcluster1.ece.utexas.edu/home/hg22723/projects/lang-cond-task-adv-augmentation/lang_cond_task_adv_augmentation/lang_data_synthesis/merge_files.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m             df_list\u001b[39m.\u001b[39mappend(pd\u001b[39m.\u001b[39mread_csv(PATH\u001b[39m+\u001b[39mf))\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bswarmcluster1.ece.utexas.edu/home/hg22723/projects/lang-cond-task-adv-augmentation/lang_cond_task_adv_augmentation/lang_data_synthesis/merge_files.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=13'>14</a>\u001b[0m merged_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mconcat(df_list, axis\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bswarmcluster1.ece.utexas.edu/home/hg22723/projects/lang-cond-task-adv-augmentation/lang_cond_task_adv_augmentation/lang_data_synthesis/merge_files.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=14'>15</a>\u001b[0m merged_df\u001b[39m.\u001b[39mto_csv(PATH\u001b[39m+\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m_\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m_\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m.csv\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(file_names[\u001b[39m0\u001b[39m],file_names[\u001b[39m1\u001b[39m],file_names[\u001b[39m2\u001b[39m]), index\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bswarmcluster1.ece.utexas.edu/home/hg22723/projects/lang-cond-task-adv-augmentation/lang_cond_task_adv_augmentation/lang_data_synthesis/merge_files.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=15'>16</a>\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(PATH\u001b[39m+\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m_\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m_\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m.csv\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(file_names[\u001b[39m0\u001b[39m],file_names[\u001b[39m1\u001b[39m],file_names[\u001b[39m2\u001b[39m]))\n",
      "File \u001b[0;32m~/anaconda3/envs/control-v11.8/lib/python3.9/site-packages/pandas/util/_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[1;32m    326\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    327\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    328\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[1;32m    329\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    330\u001b[0m     )\n\u001b[0;32m--> 331\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/control-v11.8/lib/python3.9/site-packages/pandas/core/reshape/concat.py:368\u001b[0m, in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[39m@deprecate_nonkeyword_arguments\u001b[39m(version\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, allowed_args\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39mobjs\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m    147\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mconcat\u001b[39m(\n\u001b[1;32m    148\u001b[0m     objs: Iterable[NDFrame] \u001b[39m|\u001b[39m Mapping[HashableT, NDFrame],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    157\u001b[0m     copy: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m    158\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame \u001b[39m|\u001b[39m Series:\n\u001b[1;32m    159\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    160\u001b[0m \u001b[39m    Concatenate pandas objects along a particular axis.\u001b[39;00m\n\u001b[1;32m    161\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    366\u001b[0m \u001b[39m    1   3   4\u001b[39;00m\n\u001b[1;32m    367\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 368\u001b[0m     op \u001b[39m=\u001b[39m _Concatenator(\n\u001b[1;32m    369\u001b[0m         objs,\n\u001b[1;32m    370\u001b[0m         axis\u001b[39m=\u001b[39;49maxis,\n\u001b[1;32m    371\u001b[0m         ignore_index\u001b[39m=\u001b[39;49mignore_index,\n\u001b[1;32m    372\u001b[0m         join\u001b[39m=\u001b[39;49mjoin,\n\u001b[1;32m    373\u001b[0m         keys\u001b[39m=\u001b[39;49mkeys,\n\u001b[1;32m    374\u001b[0m         levels\u001b[39m=\u001b[39;49mlevels,\n\u001b[1;32m    375\u001b[0m         names\u001b[39m=\u001b[39;49mnames,\n\u001b[1;32m    376\u001b[0m         verify_integrity\u001b[39m=\u001b[39;49mverify_integrity,\n\u001b[1;32m    377\u001b[0m         copy\u001b[39m=\u001b[39;49mcopy,\n\u001b[1;32m    378\u001b[0m         sort\u001b[39m=\u001b[39;49msort,\n\u001b[1;32m    379\u001b[0m     )\n\u001b[1;32m    381\u001b[0m     \u001b[39mreturn\u001b[39;00m op\u001b[39m.\u001b[39mget_result()\n",
      "File \u001b[0;32m~/anaconda3/envs/control-v11.8/lib/python3.9/site-packages/pandas/core/reshape/concat.py:425\u001b[0m, in \u001b[0;36m_Concatenator.__init__\u001b[0;34m(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[0m\n\u001b[1;32m    422\u001b[0m     objs \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(objs)\n\u001b[1;32m    424\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(objs) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m--> 425\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mNo objects to concatenate\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    427\u001b[0m \u001b[39mif\u001b[39;00m keys \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    428\u001b[0m     objs \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(com\u001b[39m.\u001b[39mnot_none(\u001b[39m*\u001b[39mobjs))\n",
      "\u001b[0;31mValueError\u001b[0m: No objects to concatenate"
     ]
    }
   ],
   "source": [
    "PATH= \"../bdd100k/\"\n",
    "if os.path.exists(PATH):\n",
    "    files = os.listdir(PATH)\n",
    "    \n",
    "df_list = []\n",
    "file_names = []\n",
    "for f in files:\n",
    "    if f.endswith(\".csv\"):\n",
    "        fname = f.split(\".\")[0]\n",
    "        if len(fname.split(\"_\"))==4 and fname.split(\"_\")[1]==\"captions\":\n",
    "            file_names = fname.split(\"_\")[:-1]\n",
    "            df_list.append(pd.read_csv(PATH+f))\n",
    "\n",
    "merged_df = pd.concat(df_list, axis=0)\n",
    "merged_df.to_csv(PATH+\"{}_{}_{}.csv\".format(file_names[0],file_names[1],file_names[2]), index=False)\n",
    "df = pd.read_csv(PATH+\"{}_{}_{}.csv\".format(file_names[0],file_names[1],file_names[2]))\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7000\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(PATH+\"{}_{}_{}.csv\".format(file_names[0],file_names[1],file_names[2]))\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WAYMO SYNTH\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH= \"/store/harsh/data/waymo_synthetic_ft/\"\n",
    "if os.path.exists(PATH):\n",
    "    files = os.listdir(PATH)\n",
    "    \n",
    "df_list = []\n",
    "file_names = []\n",
    "for f in files:\n",
    "    if f.endswith(\".csv\"):\n",
    "        fname = f.split(\".\")[0]\n",
    "        if len(fname.split(\"_\"))==3 and fname.split(\"_\")[0]==\"metadata\":\n",
    "            file_names = fname.split(\"_\")[:-1]\n",
    "            df_list.append(pd.read_csv(PATH+f))\n",
    "\n",
    "merged_df = pd.concat(df_list, axis=0)\n",
    "merged_df.to_csv(PATH+\"{}_{}.csv\".format(file_names[0],file_names[1]), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40000\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(PATH+\"{}_{}.csv\".format(file_names[0],file_names[1]))\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge text files to one text file ending .txt\n",
    "\n",
    "PATH= \"/store/harsh/data/waymo_synthetic_ft/\"\n",
    "if os.path.exists(PATH):\n",
    "    files = os.listdir(PATH)\n",
    "lines = []\n",
    "file_names = []\n",
    "for f in files:\n",
    "        if f.endswith(\".txt\"):\n",
    "            with open(PATH+f, \"r\") as file:\n",
    "                fname = f.split(\".\")[0]\n",
    "                if len(fname.split(\"_\"))==3 and fname.split(\"_\")[0]==\"filenames\":\n",
    "                    lines.append(file.readlines())\n",
    "    \n",
    "with open(PATH+\"filenames_seg.txt\", \"w\") as f:\n",
    "    for lines in lines:\n",
    "        f.writelines(lines)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40000\n"
     ]
    }
   ],
   "source": [
    "with open(PATH+\"filenames_seg.txt\", \"r\") as f:\n",
    "    lines = f.readlines()\n",
    "    print(len(lines))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BDD SYNTH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH= \"/store/harsh/data/bdd_synthetic_ft/\"\n",
    "if os.path.exists(PATH):\n",
    "    files = os.listdir(PATH)\n",
    "    \n",
    "df_list = []\n",
    "file_names = []\n",
    "for f in files:\n",
    "    if f.endswith(\".csv\"):\n",
    "        fname = f.split(\".\")[0]\n",
    "        if len(fname.split(\"_\"))==3 and fname.split(\"_\")[0]==\"metadata\":\n",
    "            file_names = fname.split(\"_\")[:-1]\n",
    "            df_list.append(pd.read_csv(PATH+f))\n",
    "\n",
    "merged_df = pd.concat(df_list, axis=0)\n",
    "merged_df.to_csv(PATH+\"{}_{}.csv\".format(file_names[0],file_names[1]), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42643\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(PATH+\"{}_{}.csv\".format(file_names[0],file_names[1]))\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge text files to one text file ending .txt\n",
    "\n",
    "PATH= \"/store/harsh/data/bdd_synthetic_ft/\"\n",
    "if os.path.exists(PATH):\n",
    "    files = os.listdir(PATH)\n",
    "lines = []\n",
    "file_names = []\n",
    "for f in files:\n",
    "        if f.endswith(\".txt\"):\n",
    "            with open(PATH+f, \"r\") as file:\n",
    "                fname = f.split(\".\")[0]\n",
    "                if len(fname.split(\"_\"))==3 and fname.split(\"_\")[0]==\"filenames\":\n",
    "                    lines.append(file.readlines())\n",
    "    \n",
    "with open(PATH+\"filenames_seg.txt\", \"w\") as f:\n",
    "    for lines in lines:\n",
    "        f.writelines(lines)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42642\n"
     ]
    }
   ],
   "source": [
    "with open(PATH+\"filenames_seg.txt\", \"r\") as f:\n",
    "    lines = f.readlines()\n",
    "    print(len(lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1067d00e-00000000_0_0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(lines[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the entry from "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Change the files from .npy to .png for masks to save space\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "PATH = \"/store/harsh/data/waymo_synthetic/\"\n",
    "final_files = []\n",
    "with open(PATH+\"filenames_seg.txt\", \"r\") as f:\n",
    "    lines = f.readlines()\n",
    "    print(len(lines))\n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "        if os.path.exists(PATH+\"/mask/\"+line+\".npy\"):\n",
    "            final_files.append(PATH+\"/mask/\"+line+\".npy\")\n",
    "        else:\n",
    "            print(\"The file does not exist\")\n",
    "\n",
    "print(len(final_files))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "# Load the .npy files and save them as PIL image. png files\n",
    "\n",
    "for path in final_files:\n",
    "    mask = np.load(path)\n",
    "    mask = mask.astype(np.uint8).squeeze()\n",
    "    mask = Image.fromarray(mask)\n",
    "    mask.save(path.replace(\".npy\",\".png\"))\n",
    "    # delete .npy file\n",
    "    os.remove(path)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for path in final_files:\n",
    "    # delete .npy file\n",
    "    os.remove(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "# Final check for all files\n",
    "PATH = \"/store/harsh/data/waymo_synthetic/\"\n",
    "final_files_png = []\n",
    "with open(PATH+\"filenames_seg.txt\", \"r\") as f:\n",
    "    lines = f.readlines()\n",
    "    print(len(lines))\n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "        if os.path.exists(PATH+\"/mask/\"+line+\".png\"):\n",
    "            final_files_png.append(PATH+\"/mask/\"+line+\".png\")\n",
    "        else:\n",
    "            print(\"The file does not exist\")\n",
    "\n",
    "print(len(final_files_png))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "control-v11.8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
