{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate the dataset\n",
    "## We have 4 classes of 2D data points from each quadrant of the 2D plane\n",
    "## We have an underltying functon that we would like top model, we do a symmetric sine function\n",
    "## The dataset will have datapoints from each quadrant of the 2D plane sampled disproportionately\n",
    "## The testing distributuion would be equivalent\n",
    "## We will use 2 simple MLP's to model the function and the classifications\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip uninstall torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All declarations\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All global variables\n",
    "\n",
    "TRAIN_CLASS_SEGMENTS = [0.7,0.1,0.1,0.1]\n",
    "CLASS_NAMES = ['0','1','2','3']\n",
    "CLASS_COLORS = ['red','green','blue','yellow']\n",
    "NDIM = 2\n",
    "NSAMPLES = 1000\n",
    "NCLASSES = len(CLASS_NAMES)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a simple MLP\n",
    "\n",
    "class MLP(torch.nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(MLP, self).__init__()\n",
    "        self.fc1 = torch.nn.Linear(input_size, hidden_size)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.fc2 = torch.nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = torch.nn.Softmax(dim=1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        hidden = self.fc1(x)\n",
    "        relu = self.relu(hidden)\n",
    "        output = self.fc2(relu)\n",
    "        output = self.softmax(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generating data\n",
    "\n",
    "x_train = np.random.randint(NSAMPLES, low = -5, high = 5, size = (NSAMPLES,2))\n",
    "y_class = np.zeros((NSAMPLES,))\n",
    "\n",
    "\n",
    "# Class 1\n",
    "class1 = np.where(np.logical_and(x_train[:,0] > 0, x_train[:,1] > 0))[0]\n",
    "y_class[class1] = 0\n",
    "\n",
    "# Class 2\n",
    "class2 = np.where(np.logical_and(x_train[:,0] < 0, x_train[:,1] > 0))[0]\n",
    "y_class[class2] = 1\n",
    "\n",
    "# Class 3\n",
    "class3 = np.where(np.logical_and(x_train[:,0] < 0, x_train[:,1] < 0))[0]\n",
    "y_class[class3] = 2\n",
    "\n",
    "# Class 4\n",
    "class4 = np.where(np.logical_and(x_train[:,0] > 0, x_train[:,1] < 0))[0]\n",
    "y_class[class4] = 3\n",
    "\n",
    "# Underlying function is a gaussian distribution\n",
    "y_labels = np.exp(-np.sum(x_train**2, axis = 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing the data\n",
    "\n",
    "plt.figure(figsize = (10,10))   \n",
    "for i in range(NCLASSES):\n",
    "    plt.scatter(x_train[y_class == i,0], x_train[y_class == i,1], c = CLASS_COLORS[i], label = CLASS_NAMES[i])\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "skill_disc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13 (default, Mar 28 2022, 11:38:47) \n[GCC 7.5.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e3ed66e6f1b3e04282f56eeb67588409561b9257aa131a9b235c2eb60f271515"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
